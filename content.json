{"meta":{"title":"Leo Dominic","subtitle":"愿我出走半生，归来仍是少年","description":null,"author":"Leo Dominic","url":"http://yoursite.com"},"pages":[{"title":"categories","date":"2017-05-13T03:13:13.733Z","updated":"2017-05-13T03:13:13.733Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"about me","date":"2017-04-11T15:41:37.000Z","updated":"2017-05-13T05:03:54.884Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"The Square Root of Three I fear that I will always be A lonely number like root three A three is all that's good and right Why must my three keep out of sight Beneath a vicious square-root sign? I wish instead I were a nine For nine could thwart this evil trick With just some quick arithmetic I know I'll never see the sun As 1.7321 Such is my reality A sad irrationality When,hark, just what is this I see? Another square root of a three Has quietly come waltzing by Together now we multiply To form a number we prefer Rejoicing as an integer We break free from our mortal bonds And with a wave of magic wands Our square-root signs become unglued And love for me has been renewed"},{"title":"tags","date":"2017-05-13T03:12:46.996Z","updated":"2017-05-13T03:12:46.996Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Spring cloud Eureka","slug":"spring_cloud_eureka_demo","date":"2017-06-28T13:07:37.000Z","updated":"2017-06-28T13:39:21.872Z","comments":true,"path":"2017/06/28/spring_cloud_eureka_demo/","link":"","permalink":"http://yoursite.com/2017/06/28/spring_cloud_eureka_demo/","excerpt":"","text":"Eureka 服务注册中心 新建项目 选择Spring Initializr工具新建项目，然后选择Initializr Url：https://start.spring.io 填好项目基本信息，然后选择Cloud Discovery的Eureka Server即可新建Eureka Server的项目。 修改启动程序类 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 修改配置文件application.properties 123456server.port=1111eureka.instance.hostname=localhosteureka.client.register-with-eureka=falseeureka.client.fetch-registry=falseeureka.client.serviceUrl.defaultZone=http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ eureka.client.register-with-eureka 由于该应用为注册中心，所以不需要向自己注册自己。eureka.client.fetch-registry 由于注册中心的职责是维护服务实例，他并不需要去检查服务，所以也设置为false 运行程序 一个Eureka 服务端服务端程序便已创建完成了，接下来便可以通过浏览器访问http://localhost:1111/ 访问服务，查看注册表信息。 Eureka 服务提供者 新建项目 选择Spring Initializr工具新建项目，然后选择Initializr Url：https://start.spring.io 填好项目基本信息，然后选择Web的web模块和Cloud Discovery的Eureka Discovery模块即可新建Eureka 提供者的项目。 修改启动程序类12345678@SpringBootApplication@EnableEurekaClientpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 1234567@RestControllerpublic class HelloController &#123; @RequestMapping(value = \"/hello\", method = RequestMethod.GET) public String home()&#123; return \"Hello World\"; &#125;&#125; 这里@EnableEurekaClient也可以用：@EnableDiscoveryClient 修改配置文件application.properties 12spring.application.name=hello-serviceeureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/ 运行程序 一个Eureka 服务提供者程序便已创建完成了，接下来便可以通过浏览器访问http://localhost:1111/ 访问服务，查看注册表信息。看服务有没有被注册上 Eureka 服务消费者 新建项目 和服务提供者一样 修改启动程序类12345678910111213@SpringBootApplication@EnableDiscoveryClientpublic class EurekaConsumerApplication &#123; @Bean @LoadBalanced RestTemplate restTemplate()&#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(EurekaConsumerApplication.class, args); &#125;&#125; 12345678910@RestControllerpublic class ConsumerController &#123; @Resource RestTemplate restTemplate; @RequestMapping(value = \"/ribbon-consumer\",method = RequestMethod.GET) public String helloConsumer()&#123; return restTemplate.getForEntity(\"http://HELLO-SERVICE/hello\", String.class).getBody(); &#125;&#125; 这里@EnableEurekaClient也可以用：@EnableDiscoveryClient 修改配置文件application.properties 123spring.application.name=ribbon-consumerserver.port=9000eureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/ 由于8080端口已经被提供者占用，所以这里将端口改为9000 运行程序 一个Eureka 服务提供者程序便已创建完成了，接下来便可以通过浏览器访问http://localhost:1111/ 访问服务，查看注册表信息。看服务有没有被注册上 消费者调用提供者 在浏览器输入http://localhost/ribbon-consumer 看结果，如果页面显示hello world说明程序运行没有问题。 结语到这里一个简单的Eureka 注册中心，服务提供者，服务消费者demo就完成了，感谢浏览。","categories":[{"name":"Spring cloud","slug":"Spring-cloud","permalink":"http://yoursite.com/categories/Spring-cloud/"}],"tags":[{"name":"Spring cloud","slug":"Spring-cloud","permalink":"http://yoursite.com/tags/Spring-cloud/"},{"name":"Eureka","slug":"Eureka","permalink":"http://yoursite.com/tags/Eureka/"}]},{"title":"Dubbo Rest协议支持","slug":"dubbo_rest","date":"2017-06-27T02:07:37.000Z","updated":"2017-06-27T13:00:22.384Z","comments":true,"path":"2017/06/27/dubbo_rest/","link":"","permalink":"http://yoursite.com/2017/06/27/dubbo_rest/","excerpt":"","text":"简介 通常我们知道dubbo支持Dubbo，Rmi，Hessian协议等协议，但有时候我们需要让服务支持rest协议，dubbo 2.8.4正好解决这个问题。 依赖 spring dubbo netty 配置12345&lt;dubbo:application name=\"xxx\" owner=\"xx\" organization=\"xx\"/&gt;&lt;dubbo:registry address=\"multicast://224.5.6.7:1234\"/&gt;&lt;dubbo:protocol id=\"xx\" name=\"rest\" port=\"xx\" keepalive=\"true\" server=\"netty\" iothreads=\"5\" threads=\"100\" chartset=\"utf-8\"/&gt;&lt;dubbo:annotation package=\"xx.xx.xx\"/&gt; 接口（没有接口会报错）123456public interface EatServer &#123; /** *@Valid 采用hibernate验证参数 */ String eat(@Valid Food food);&#125; 提供服务（即接口实现）123456789101112131415161718@Service #(spring)@Service( version=\"0.0.1\", timeout=5000, retries=2, validation=\"true\")@Path(\"/\")public class EatServer implements EatServer &#123; @Path(\"eat\") @Post @Produces(&#123;ContentType.APPLICATION_JSON_UTF_8&#125;) @Consumes(&#123;ContentType.APPLICATION_JSON_UTF_8&#125;) String eat(@Valid Food food)&#123; .... &#125;&#125;","categories":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://yoursite.com/categories/Dubbo/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://yoursite.com/tags/Dubbo/"},{"name":"Rest","slug":"Rest","permalink":"http://yoursite.com/tags/Rest/"}]},{"title":"基于 Token 的身份验证","slug":"token_signature","date":"2017-05-18T02:07:37.000Z","updated":"2017-05-18T14:29:47.038Z","comments":true,"path":"2017/05/18/token_signature/","link":"","permalink":"http://yoursite.com/2017/05/18/token_signature/","excerpt":"","text":"基于 Token 的身份验证[转载]转载地址：链接 最近了解下基于 Token 的身份验证，跟大伙分享下。很多大型网站也都在用，比如 Facebook，Twitter，Google+，Github 等等，比起传统的身份验证方法，Token 扩展性更强，也更安全点，非常适合用在 Web 应用或者移动应用上。Token 的中文有人翻译成 “令牌”，我觉得挺好，意思就是，你拿着这个令牌，才能过一些关卡。 传统身份验证的方法HTTP 是一种没有状态的协议，也就是它并不知道是谁是访问应用。这里我们把用户看成是客户端，客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求时候，还得再验证一下。 解决的方法就是，当用户请求登录的时候，如果没有问题，我们在服务端生成一条记录，这个记录里可以说明一下登录的用户是谁，然后把这条记录的 ID 号发送给客户端，客户端收到以后把这个 ID 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候，可以带着这个 Cookie ，这样服务端会验证一个这个 Cookie 里的信息，看看能不能在服务端这里找到对应的记录，如果可以，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。 上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端定期的去清理过期的 Session 。 基于 Token 的身份验证方法使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的： 客户端使用用户名跟密码请求登录服务端收到请求，去验证用户名与密码验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里客户端每次向服务端请求资源的时候需要带着服务端签发的 Token服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据 JWT实施 Token 验证的方法挺多的，还有一些标准方法，比如 JWT，读作：jot ，表示：JSON Web Tokens 。JWT 标准的 Token 有三个部分：headerpayloadsignature中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样：1eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc 1.Headerheader 部分主要是两部分内容，一个是 Token 的类型，另一个是使用的算法，比如下面类型就是 JWT，使用的算法是 HS256。1234&#123; \"typ\": \"JWT\", \"alg\": \"HS256\"&#125; 上面的内容要用 Base64 的形式编码一下，所以就变成这样：1eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9 2.PayloadPayload 里面是 Token 的具体内容，这些内容里面有一些是标准字段，你也可以添加其它需要的内容。下面是标准字段： iss：Issuer，发行者sub：Subject，主题aud：Audience，观众exp：Expiration time，过期时间nbf：Not beforeiat：Issued at，发行时间jti：JWT ID比如下面这个 Payload ，用到了 iss 发行人，还有 exp 过期时间。另外还有两个自定义的字段，一个是 name ，还有一个是 admin 。123456&#123; \"iss\": \"ninghao.net\", \"exp\": \"1438955445\", \"name\": \"wanghao\", \"admin\": true&#125; 使用 Base64 编码以后就变成了这个样子：1eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ 3.SignatureJWT 的最后一部分是 Signature ，这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。12345headerpayloadsecretvar encodedString = base64UrlEncode(header) + \".\" + base64UrlEncode(payload); HMACSHA256(encodedString, 'secret'); 处理完成以后看起来像这样：1SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc 最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样：1eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc 客户端收到这个 Token 以后把它存储下来，下回向服务端发送请求的时候就带着这个 Token 。服务端收到这个 Token ，然后进行验证，通过以后就会返回给客户端想要的资源。 相关链接 http://jwt.io/https://github.com/firebase/php-jwthttps://scotch.io/tutorials/the-anatomy-of-a-json-web-tokenhttps://github.com/auth0/jwt-decode","categories":[{"name":"Token","slug":"Token","permalink":"http://yoursite.com/categories/Token/"}],"tags":[{"name":"Token","slug":"Token","permalink":"http://yoursite.com/tags/Token/"},{"name":"JWT","slug":"JWT","permalink":"http://yoursite.com/tags/JWT/"}]},{"title":"Linux性能检查工具","slug":"linux_command_performance","date":"2017-05-17T02:07:37.000Z","updated":"2017-05-18T14:28:13.651Z","comments":true,"path":"2017/05/17/linux_command_performance/","link":"","permalink":"http://yoursite.com/2017/05/17/linux_command_performance/","excerpt":"","text":"Linux性能检查工具一、TopTOP是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定.top - 12:38:33 up 50 days, 23:15, 7 users, load average: 60.58, 61.14, 61.22Tasks: 203 total, 60 running, 139 sleeping, 4 stopped, 0 zombieCpu(s) : 27.0%us, 73.0%sy, 0.0%ni, 0.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1939780k total, 1375280k used, 564500k free, 109680k buffersSwap: 4401800k total, 497456k used, 3904344k free, 848712k cachedPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 4338 oracle 25 0 627m 209m 207m R 0 11.0 297:14.76 oracle 4267 oracle 25 0 626m 144m 143m R 6 7.6 89:16.62 oracle 3458 oracle 25 0 672m 133m 124m R 0 7.1 1283:08 oracle 3478 oracle 25 0 672m 124m 115m R 0 6.6 1272:30 oracle 3395 oracle 25 0 672m 122m 113m R 0 6.5 1270:03 oracle A. TOP前五行统计信息统计信息区前五行是系统整体的统计信息。 1. 第一行是任务队列信息同 uptime 命令的执行结果:12[root@localhost ~]# uptime 13:22:30 up 8 min, 4 users, load average: 0.14, 0.38, 0.25 其内容如下: 值 说明 12:38:33 当前时间 up 50days 系统运行时间，格式为时:分 1 user 当前登录用户数 load average: 0.06, 0.60, 0.48 系统负载，即任务队列的平均长度。 三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。 2. 第二、三行为进程和CPU的信息当有多个CPU时，这些内容可能会超过两行。内容如下： 值 说明 Tasks: 29 total 进程总数 1 running 正在运行的进程数 28 sleeping 睡眠的进程数 0 stopped 停止的进程数 0 zombie 僵尸进程数 Cpu(s): 0.3% us 用户空间占用CPU百分比 1.0% sy 内核空间占用CPU百分比 0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比 98.7% id 空闲CPU百分比 0.0% wa 等待输入输出的CPU时间百分比 0.0% hi 0.0% si 3. 第四五行为内存信息。内容如下： 值 说明 Mem: 191272k total 物理内存总量 173656k used 使用的物理内存总量 17616k free 空闲内存总量 22052k buffers 用作内核缓存的内存量 Swap: 192772k total 交换区总量 0k used 使用的交换区总量 192772k free 空闲交换区总量 123988k cached 缓冲的交换区总量。 内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖， 该数值即为这些内容已存在于内存中的交换区的大小。相应的内存再次被换出时可不必再对交换区写入。 B. 进程信息 列名 含义 PID 进程id PPID 父进程id RUSER Real user name UID 进程所有者的用户id USER 进程所有者的用户名 GROUP 进程所有者的组名 TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? PR 优先级 NI nice值。负值表示高优先级，正值表示低优先级 P 最后使用的CPU，仅在多CPU环境下有意义 %CPU 上次更新到现在的CPU时间占用百分比 TIME 进程使用的CPU时间总计，单位秒 TIME+ 进程使用的CPU时间总计，单位1/100秒 %MEM 进程使用的物理内存百分比 VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA CODE 可执行代码占用的物理内存大小，单位kb DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb SHR 共享内存大小，单位kb nFLT 页面错误次数 nDRT 最后一次写入到现在，被修改过的页面数。 S 进程状态。D=不可中断的睡眠状态;R=运行;S=睡眠;T=跟踪/停止;Z=僵尸进程 COMMAND 命令名/命令行 WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 Flags 任务标志，参考 sched.h 二、vmstat一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如: root@ubuntu:~# vmstat 2 1 procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu---- r b swpd free buff cache si so bi bo in cs us sy id wa 1 0 0 3498472 315836 3819540 0 0 0 1 2 0 0 0 100 0 2表示每个两秒采集一次服务器状态，1表示只采集一次(如果想一只采集第二个参数不写就可以，这表示vmstat每2秒采集数据，一直采集，直到我结束程序)。 1、r表示运行队列(就是说多少个进程真的分配到CPU)，我测试的服务器目前CPU比较空闲，没什么程序在跑，当这个值超过了CPU数目，就会出现CPU瓶颈了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。 2、b表示阻塞的进程,这个不多说，进程阻塞，大家懂的。 3、swpd虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。 4、free空闲的物理内存的大小，我的机器内存总共8G，剩余3415M。 5、buffLinux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存，我本机大概占用300多M 6、cachecache直接用来记忆我们打开的文件,给文件做缓冲，我本机大概占用300多M(这里是Linux/Unix的聪明之处，把空闲的物理内存的一部分拿来做文件和目录的缓存，是为了提高 程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。) 7、si每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。我的机器内存充裕，一切正常。 8、so每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。 9、bi块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte，我本机上没什么IO操作，所以一直是0，但是我曾在处理拷贝大量数据(2-3T)的机器上看过可以达到140000/s，磁盘写入速度差不多140M每秒 10、bo块设备每秒发送的块数量，例如我们读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。 11、in每秒CPU的中断次数，包括时间中断 12、cs每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。 13、us用户CPU时间，我曾经在一个做加密解密很频繁的服务器上，可以看到us接近100,r运行队列达到80(机器在做压力测试，性能表现不佳)。 14、sy系统CPU时间，如果太高，表示系统调用时间长，例如是IO操作频繁。 15、id空闲 CPU时间，一般来说，id + us + sy = 100,一般我认为id是空闲CPU使用率，us是用户CPU使用率，sy是系统CPU使用率。 16、wt等待IO CPU时间。 三、sarsar（System Activity Reporter系统活动情况报告）是目前 Linux 上最为全面的系统性能分析工具之一，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动等。本文主要以CentOS 6.3 x64系统为例，介绍sar命令。 sar命令常用格式 sar [options] [-A] [-o file] t [n] 其中： t为采样间隔，n为采样次数，默认值是1； -o file表示将命令结果以二进制格式存放在文件中，file 是文件名。 options 为命令行选项，sar命令常用选项如下： -A：所有报告的总和 -u：输出CPU使用情况的统计信息 -v：输出inode、文件和其他内核表的统计信息 -d：输出每一个块设备的活动信息 -r：输出内存和交换空间的统计信息 -b：显示I/O和传送速率的统计信息 -a：文件读写情况 -c：输出进程统计信息，每秒创建的进程数 -R：输出内存页面的统计信息 -y：终端设备活动情况 -w：输出系统交换活动信息 1. CPU资源监控例如，每10秒采样一次，连续采样3次，观察CPU 的使用情况，并将采样结果以二进制形式存入当前目录下的文件test中，需键入如下命令： sar -u -o test 10 3 屏幕显示如下： 17:06:16 CPU %user %nice %system %iowait %steal %idle 17:06:26 all 0.00 0.00 0.20 0.00 0.00 99.80 17:06:36 all 0.00 0.00 0.20 0.00 0.00 99.80 17:06:46 all 0.00 0.00 0.10 0.00 0.00 99.90 Average: all 0.00 0.00 0.17 0.00 0.00 99.83 输出项说明： CPU：all 表示统计信息为所有 CPU 的平均值。 %user：显示在用户级别(application)运行使用 CPU 总时间的百分比。 %nice：显示在用户级别，用于nice操作，所占用 CPU 总时间的百分比。 %system：在核心级别(kernel)运行所使用 CPU 总时间的百分比。 %iowait：显示用于等待I/O操作占用 CPU 总时间的百分比。 %steal：管理程序(hypervisor)为另一个虚拟进程提供服务而等待虚拟 CPU 的百分比。 %idle：显示 CPU 空闲时间占用 CPU 总时间的百分比。 1. 若 %iowait 的值过高，表示硬盘存在I/O瓶颈 2. 若 %idle 的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量 3. 若 %idle 的值持续低于1，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU 。 如果要查看二进制文件test中的内容，需键入如下sar命令： sar -u -f test 2. inode、文件和其他内核表监控例如，每10秒采样一次，连续采样3次，观察核心表的状态，需键入如下命令： sar -v 10 3 屏幕显示如下： 17:10:49 dentunusd file-nr inode-nr pty-nr 17:10:59 6301 5664 12037 4 17:11:09 6301 5664 12037 4 17:11:19 6301 5664 12037 4 Average: 6301 5664 12037 4 输出项说明： dentunusd：目录高速缓存中未被使用的条目数量 file-nr：文件句柄（file handle）的使用数量 inode-nr：索引节点句柄（inode handle）的使用数量 pty-nr：使用的pty数量 3. 内存和交换空间监控例如，每10秒采样一次，连续采样3次，监控内存分页： sar -r 10 3 屏幕显示如下： 16时55分22秒 kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty 16时55分32秒 135784 3740856 96.50 202708 364664 7719184 63.96 2477312 900676 76 16时55分42秒 135484 3741156 96.51 202716 364716 7719184 63.96 2477196 900740 28 16时55分52秒 135356 3741284 96.51 202732 364716 7719184 63.96 2477316 900772 72 平均时间: 135541 3741099 96.50 202719 364699 7719184 63.96 2477275 900729 59 输出项说明： kbmemfree：这个值和free命令中的free值基本一致,所以它不包括buffer和cache的空间. kbmemused：这个值和free命令中的used值基本一致,所以它包括buffer和cache的空间. %memused：这个值是kbmemused和内存总量(不包括swap)的一个百分比. kbbuffers和kbcached：这两个值就是free命令中的buffer和cache. kbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap). %commit：这个值是kbcommit与内存总量(包括swap)的一个百分比. 4. 内存分页监控例如，每10秒采样一次，连续采样3次，监控内存分页： sar -B 10 3 屏幕显示如下： 16时57分02秒 pgpgin/s pgpgout/s fault/s majflt/s pgfree/s pgscank/s pgscand/s pgsteal/s %vmeff 16时57分12秒 1.60 14.40 12318.40 0.10 3418.40 0.00 0.00 0.00 0.00 16时57分22秒 3.20 11.60 12504.20 0.10 3484.60 0.00 0.00 0.00 0.00 16时57分32秒 0.00 12.00 12298.70 0.00 3407.50 0.00 0.00 0.00 0.00 平均时间: 1.60 12.67 12373.77 0.07 3436.83 0.00 0.00 0.00 0.00 输出项说明： pgpgin/s：表示每秒从磁盘或SWAP置换到内存的字节数(KB) pgpgout/s：表示每秒从内存置换到磁盘或SWAP的字节数(KB) fault/s：每秒钟系统产生的缺页数,即主缺页与次缺页之和(major + minor) majflt/s：每秒钟产生的主缺页数. pgfree/s：每秒被放入空闲队列中的页个数 pgscank/s：每秒被kswapd扫描的页个数 pgscand/s：每秒直接被扫描的页个数 pgsteal/s：每秒钟从cache中被清除来满足内存需要的页个数 %vmeff：每秒清除的页(pgsteal)占总扫描页(pgscank+pgscand)的百分比 5. I/O和传送速率监控例如，每10秒采样一次，连续采样3次，报告缓冲区的使用情况，需键入如下命令： sar -b 10 3 屏幕显示如下： 18:51:05 tps rtps wtps bread/s bwrtn/s 18:51:15 0.00 0.00 0.00 0.00 0.00 18:51:25 1.92 0.00 1.92 0.00 22.65 18:51:35 0.00 0.00 0.00 0.00 0.00 Average: 0.64 0.00 0.64 0.00 7.59 输出项说明： tps：每秒钟物理设备的 I/O 传输总量 rtps：每秒钟从物理设备读入的数据总量 wtps：每秒钟向物理设备写入的数据总量 bread/s：每秒钟从物理设备读入的数据量，单位为 块/s bwrtn/s：每秒钟向物理设备写入的数据量，单位为 块/s 6. 进程队列长度和平均负载状态监控例如，每10秒采样一次，连续采样3次，监控进程队列长度和平均负载状态： sar -q 10 3 屏幕显示如下： 19:25:50 runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 19:26:00 0 259 0.00 0.00 0.00 19:26:10 0 259 0.00 0.00 0.00 19:26:20 0 259 0.00 0.00 0.00 Average: 0 259 0.00 0.00 0.00 输出项说明： runq-sz：运行队列的长度（等待运行的进程数） plist-sz：进程列表中进程（processes）和线程（threads）的数量 ldavg-1：最后1分钟的系统平均负载（System load average） ldavg-5：过去5分钟的系统平均负载 ldavg-15：过去15分钟的系统平均负载 7. 系统交换活动信息监控例如，每10秒采样一次，连续采样3次，监控系统交换活动信息： sar - W 10 3 屏幕显示如下： 19:39:50 pswpin/s pswpout/s 19:40:00 0.00 0.00 19:40:10 0.00 0.00 19:40:20 0.00 0.00 Average: 0.00 0.00 输出项说明： pswpin/s：每秒系统换入的交换页面（swap page）数量 pswpout/s：每秒系统换出的交换页面（swap page）数量 8. 设备使用情况监控例如，每10秒采样一次，连续采样3次，报告设备使用情况，需键入如下命令： sar -d 10 3 –p 屏幕显示如下： 17:45:54 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 17:46:04 scd0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 17:46:04 sda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 17:46:04 vg_livedvd-lv_root 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 17:46:04 vg_livedvd-lv_swap 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 其中： 参数-p可以打印出sda,hdc等磁盘设备名称,如果不用参数-p,设备节点则有可能是dev8-0,dev22-0 tps:每秒从物理磁盘I/O的次数.多个逻辑请求会被合并为一个I/O磁盘请求,一次传输的大小是不确定的. rd_sec/s:每秒读扇区的次数. wr_sec/s:每秒写扇区的次数. avgrq-sz:平均每次设备I/O操作的数据大小(扇区). avgqu-sz:磁盘请求队列的平均长度. await:从请求磁盘操作到系统完成处理,每次请求的平均消耗时间,包括请求队列等待时间,单位是毫秒(1秒=1000毫秒). svctm:系统处理每次请求的平均时间,不包括在请求队列中消耗的时间. %util:I/O请求占CPU的百分比,比率越大,说明越饱和. 1. avgqu-sz 的值较低时，设备的利用率较高。 2. 当%util的值接近 1% 时，表示设备带宽已经占满。 9. 总结要判断系统瓶颈问题，有时需几个 sar 命令选项结合起来怀疑CPU存在瓶颈，可用 sar -u 和 sar -q 等来查看怀疑内存存在瓶颈，可用 sar -B、sar -r 和 sar -W 等来查看怀疑I/O存在瓶颈，可用 sar -b、sar -u 和 sar -d 等来查看 四、mpstatmpstat是Multiprocessor Statistics的缩写，是实时系统监控工具。其报告与CPU的一些统计信息，这些信息存放在/proc/stat文件中。在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。mpstat最大的特点是：可以查看多核心cpu中每个计算核心的统计数据；而类似工具vmstat只能查看系统整体cpu情况。 语法 mpstat [-P {|ALL}] [internal [count]] 参数 解释 -P {|ALL} 表示监控哪个CPU， cpu在[0,cpu个数-1]中取值 internal 相邻的两次采样的间隔时间、 count 采样的次数，count只能和delay一起使用 当没有参数时，mpstat则显示系统启动以后所有信息的平均值。有interval时，第一行的信息自系统启动以来的平均信息。从第二行开始，输出为前一个interval时间段的平均信息。 如果要看每个cpu核心的详细当前运行状况信息，输出如下： mpstat -P ALL 2 19:43:58 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %idle 19:43:59 all 0.00 0.00 0.04 0.00 0.00 0.00 0.00 0.00 99.96 19:43:59 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 19:43:59 1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 ....... 19:43:59 13 0.99 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.01 19:43:59 14 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 19:43:59 15 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 复制代码 字段的含义如下 %user 在internal时间段里，用户态的CPU时间(%)，不包含nice值为负进程 (usr/total)*100 %nice 在internal时间段里，nice值为负进程的CPU时间(%) (nice/total)*100 %sys 在internal时间段里，内核时间(%) (system/total)*100 %iowait 在internal时间段里，硬盘IO等待时间(%) (iowait/total)*100 %irq 在internal时间段里，硬中断时间(%) (irq/total)*100 %soft 在internal时间段里，软中断时间(%) (softirq/total)*100 %idle 在internal时间段里，CPU除去等待磁盘IO操作外的因为任何原因而空闲的时间闲置时间(%) (idle/total)*100 计算公式如下 total_cur=user+system+nice+idle+iowait+irq+softirq total_pre=pre_user+ pre_system+ pre_nice+ pre_idle+ pre_iowait+ pre_irq+ pre_softirq user=user_cur – user_pre total=total_cur-total_pre 其中_cur 表示当前值，_pre表示interval时间前的值。上表中的所有值可取到两位小数点。 五、iostat1、简介iostat主要用于监控系统设备的IO负载情况，iostat首次运行时显示自系统启动开始的各项统计信息，之后运行iostat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息。 2、语法 iostat [ -c ] [ -d ] [ -h ] [ -N ] [ -k | -m ] [ -t ] [ -V ] [ -x ] [ -z ] [ device [...] | ALL ] [ -p [ device [,...] | ALL ] ] [ interval [ count ] ] 3、入门使用 iostat -d -k 2 参数 -d 表示，显示设备（磁盘）使用状态；-k某些使用block为单位的列强制使用Kilobytes为单位；2表示，数据显示每隔2秒刷新一次。 输出如下 iostat -d -k 1 10 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 39.29 21.14 1.44 441339807 29990031 sda1 0.00 0.00 0.00 1623 523 sda2 1.32 1.43 4.54 29834273 94827104 sda3 6.30 0.85 24.95 17816289 520725244 sda5 0.85 0.46 3.40 9543503 70970116 sda6 0.00 0.00 0.00 550 236 sda7 0.00 0.00 0.00 406 0 sda8 0.00 0.00 0.00 406 0 sda9 0.00 0.00 0.00 406 0 sda10 60.68 18.35 71.43 383002263 1490928140 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 327.55 5159.18 102.04 5056 100 sda1 0.00 0.00 0.00 0 0 输出信息的意义 tps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。\"一次传输\"意思是\"一次I/O请求\"。多个逻辑请求可能会被合并为\"一次I/O请求\"。\"一次传输\"请求的大小是未知的。 kB_read/s：每秒从设备（drive expressed）读取的数据量； kB_wrtn/s：每秒向设备（drive expressed）写入的数据量； kB_read：读取的总数据量； kB_wrtn：写入的总数量数据量；这些单位都为Kilobytes。 上面的例子中，我们可以看到磁盘sda以及它的各个分区的统计数据，当时统计的磁盘总TPS是39.29，下面是各个分区的TPS。（因为是瞬间值，所以总TPS并不严格等于各个分区TPS的总和） 指定监控的设备名称为sda，该命令的输出结果和上面命令完全相同。 iostat -d sda 2 默认监控所有的硬盘设备，现在指定只监控sda。 -x 参数 iostat还有一个比较常用的选项-x，该选项将用于显示和io相关的扩展数据。 iostat -d -x -k 1 10 Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util sda 1.56 28.31 7.80 31.49 42.51 2.92 21.26 1.46 1.16 0.03 0.79 2.62 10.28 Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util sda 2.00 20.00 381.00 7.00 12320.00 216.00 6160.00 108.00 32.31 1.75 4.50 2.17 84.20 输出信息的含义 rrqm/s：每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge）；wrqm/s：每秒这个设备相关的写入请求有多少被Merge了。 rsec/s：每秒读取的扇区数； wsec/：每秒写入的扇区数。 rKB/s：The number of read requests that were issued to the device per second； wKB/s：The number of write requests that were issued to the device per second； avgrq-sz 平均请求扇区的大小 avgqu-sz 是平均请求队列的长度。毫无疑问，队列长度越短越好。 await： 每一个IO请求的处理的平均时间（单位是微秒毫秒）。这里可以理解为IO的响应时间，一般地系统IO响应时间应该低于5ms，如果大于10ms就比较大了。 这个时间包括了队列时间和服务时间，也就是说，一般情况下，await大于svctm，它们的差值越小，则说明队列时间越短，反之差值越大，队列时间越长，说明系统出了问题。 svctm 表示平均每次设备I/O操作的服务时间（以毫秒为单位）。如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长， 系统上运行的应用程序将变慢。 %util： 在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util = 0.8/1 = 80%，所以该参数暗示了设备的繁忙程度 。一般地，如果该参数是100%表示设备已经接近满负荷运行了（当然如果是多磁盘，即使%util是100%，因为磁盘的并发能力，所以磁盘使用未必就到了瓶颈）。 -c 参数 iostat还可以用来获取cpu部分状态值： iostat -c 1 10 avg-cpu: %user %nice %sys %iowait %idle 1.98 0.00 0.35 11.45 86.22 avg-cpu: %user %nice %sys %iowait %idle 1.62 0.00 0.25 34.46 63.67 常见用法 iostat -d -k 1 10 #查看TPS和吞吐量信息(磁盘读写速度单位为KB) iostat -d -m 2 #查看TPS和吞吐量信息(磁盘读写速度单位为MB) iostat -d -x -k 1 10 #查看设备使用率（%util）、响应时间（await） iostat -c 1 10 #查看cpu状态 实例分析 ostat -d -k 1 |grep sda10 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda10 60.72 18.95 71.53 395637647 1493241908 sda10 299.02 4266.67 129.41 4352 132 sda10 483.84 4589.90 4117.17 4544 4076 sda10 218.00 3360.00 100.00 3360 100 sda10 546.00 8784.00 124.00 8784 124 sda10 827.00 13232.00 136.00 13232 136 上面看到，磁盘每秒传输次数平均约400；每秒磁盘读取约5MB，写入约1MB。 iostat -d -x -k 1 Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util sda 1.56 28.31 7.84 31.50 43.65 3.16 21.82 1.58 1.19 0.03 0.80 2.61 10.29 sda 1.98 24.75 419.80 6.93 13465.35 253.47 6732.67 126.73 32.15 2.00 4.70 2.00 85.25 sda 3.06 41.84 444.90 54.08 14204.08 2048.98 7102.04 1024.49 32.57 2.10 4.21 1.85 92.24 可以看到磁盘的平均响应时间80。磁盘响应正常，但是已经很繁忙了。 六、netstat1、简介Netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade 连接，多播成员 (Multicast Memberships) 等等。 2、输出信息含义执行netstat后，其输出结果为 Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 2 210.34.6.89:telnet 210.34.6.96:2873 ESTABLISHED tcp 296 0 210.34.6.89:1165 210.34.6.84:netbios-ssn ESTABLISHED tcp 0 0 localhost.localdom:9001 localhost.localdom:1162 ESTABLISHED tcp 0 0 localhost.localdom:1162 localhost.localdom:9001 ESTABLISHED tcp 0 80 210.34.6.89:1161 210.34.6.10:netbios-ssn CLOSE Active UNIX domain sockets (w/o servers) Proto RefCnt Flags Type State I-Node Path unix 1 [ ] STREAM CONNECTED 16178 @000000dd unix 1 [ ] STREAM CONNECTED 16176 @000000dc unix 9 [ ] DGRAM 5292 /dev/log unix 1 [ ] STREAM CONNECTED 16182 @000000df 从整体上看，netstat的输出结果可以分为两个部分：一个是Active Internet connections，称为有源TCP连接，其中”Recv-Q”和”Send-Q”指%0A的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。 3、常见参数-a (all)显示所有选项，默认不显示LISTEN相关-t (tcp)仅显示tcp相关选项-u (udp)仅显示udp相关选项-n 拒绝显示别名，能显示数字的全部转化成数字。-l 仅列出有在 Listen (监听) 的服務状态 -p 显示建立相关链接的程序名-r 显示路由信息，路由表-e 显示扩展信息，例如uid等-s 按各个协议进行统计-c 每隔一个固定时间，执行该netstat命令。 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到 4、实用命令实例列出所有端口 (包括监听和未监听的) 列出所有端口 netstat -a netstat -a | more Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:30037 *:* LISTEN udp 0 0 *:bootpc *:* 列出所有 tcp 端口 netstat -at netstat -at Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:30037 *:* LISTEN tcp 0 0 localhost:ipp *:* LISTEN tcp 0 0 *:smtp *:* LISTEN tcp6 0 0 localhost:ipp [::]:* LISTEN 列出所有 udp 端口 netstat -au netstat -au Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State udp 0 0 *:bootpc *:* udp 0 0 *:49119 *:* udp 0 0 *:mdns *:* 列出所有处于监听状态的 Sockets 只显示监听端口 netstat -l netstat -l Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:ipp *:* LISTEN tcp6 0 0 localhost:ipp [::]:* LISTEN udp 0 0 *:49119 *:* 只列出所有监听 tcp 端口 netstat -lt netstat -lt Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:30037 *:* LISTEN tcp 0 0 *:smtp *:* LISTEN tcp6 0 0 localhost:ipp [::]:* LISTEN 只列出所有监听 udp 端口 netstat -lu netstat -lu Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State udp 0 0 *:49119 *:* udp 0 0 *:mdns *:* 只列出所有监听 UNIX 端口 netstat -lx netstat -lx Active UNIX domain sockets (only servers) Proto RefCnt Flags Type State I-Node Path unix 2 [ ACC ] STREAM LISTENING 6294 private/maildrop unix 2 [ ACC ] STREAM LISTENING 6203 public/cleanup unix 2 [ ACC ] STREAM LISTENING 6302 private/ifmail unix 2 [ ACC ] STREAM LISTENING 6306 private/bsmtp 显示每个协议的统计信息 显示所有端口的统计信息 netstat -s netstat -s Ip: 11150 total packets received 1 with invalid addresses 0 forwarded 0 incoming packets discarded 11149 incoming packets delivered 11635 requests sent out Icmp: 0 ICMP messages received 0 input ICMP message failed. Tcp: 582 active connections openings 2 failed connection attempts 25 connection resets received Udp: 1183 packets received 4 packets to unknown port received. ..... 显示 TCP 或 UDP 端口的统计信息 netstat -st 或 -su netstat -st netstat -su 在 netstat 输出中显示 PID 和进程名称 netstat -p netstat -p 可以与其它开关一起使用，就可以添加 “PID/进程名称” 到 netstat 输出中，这样 debugging 的时候可以很方便的发现特定端口运行的程序。 netstat -pt Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 1 0 ramesh-laptop.loc:47212 192.168.185.75:www CLOSE_WAIT 2109/firefox tcp 0 0 ramesh-laptop.loc:52750 lax:www ESTABLISHED 2109/firefox 在 netstat 输出中不显示主机，端口和用户名 (host, port or user) 当你不想让主机，端口和用户名显示，使用 netstat -n。将会使用数字代替那些名称。 同样可以加速输出，因为不用进行比对查询。 netstat -an 如果只是不想让这三个名称中的一个被显示，使用以下命令 netsat -a --numeric-ports netsat -a --numeric-hosts netsat -a --numeric-users 持续输出 netstat 信息 netstat 将每隔一秒输出网络信息。 netstat -c Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 ramesh-laptop.loc:36130 101-101-181-225.ama:www ESTABLISHED tcp 1 1 ramesh-laptop.loc:52564 101.11.169.230:www CLOSING tcp 0 0 ramesh-laptop.loc:43758 server-101-101-43-2:www ESTABLISHED tcp 1 1 ramesh-laptop.loc:42367 101.101.34.101:www CLOSING 显示系统不支持的地址族 (Address Families) netstat --verbose 在输出的末尾，会有如下的信息 netstat: no support for `AF IPX' on this system. netstat: no support for `AF AX25' on this system. netstat: no support for `AF X25' on this system. netstat: no support for `AF NETROM' on this system. 显示核心路由信息 netstat -r netstat -r Kernel IP routing table Destination Gateway Genmask Flags MSS Window irtt Iface 192.168.1.0 * 255.255.255.0 U 0 0 0 eth2 link-local * 255.255.0.0 U 0 0 0 eth2 default 192.168.1.1 0.0.0.0 UG 0 0 0 eth2 注意： 使用 netstat -rn 显示数字格式，不查询主机名称。 找出程序运行的端口 并不是所有的进程都能找到，没有权限的会不显示，使用 root 权限查看所有的信息。 netstat -ap | grep ssh tcp 1 0 dev-db:ssh 101.174.100.22:39213 CLOSE_WAIT - tcp 1 0 dev-db:ssh 101.174.100.22:57643 CLOSE_WAIT - 找出运行在指定端口的进程 netstat -an | grep ':80' 显示网络接口列表 netstat -i Kernel Interface table Iface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth0 1500 0 0 0 0 0 0 0 0 0 BMU eth2 1500 0 26196 0 0 0 26883 6 0 0 BMRU lo 16436 0 4 0 0 0 4 0 0 0 LRU 显示详细信息，像是 ifconfig 使用 netstat -ie: netstat -ie Kernel Interface table eth0 Link encap:Ethernet HWaddr 00:10:40:11:11:11 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) Memory:f6ae0000-f6b00000","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"top","slug":"top","permalink":"http://yoursite.com/tags/top/"},{"name":"vmstat","slug":"vmstat","permalink":"http://yoursite.com/tags/vmstat/"},{"name":"sar","slug":"sar","permalink":"http://yoursite.com/tags/sar/"},{"name":"iostat","slug":"iostat","permalink":"http://yoursite.com/tags/iostat/"},{"name":"netstat","slug":"netstat","permalink":"http://yoursite.com/tags/netstat/"}]},{"title":"Docker安装Elasticsearch集群","slug":"elasticsearch_cluster_docker","date":"2017-05-16T02:07:37.000Z","updated":"2017-05-16T15:22:03.514Z","comments":true,"path":"2017/05/16/elasticsearch_cluster_docker/","link":"","permalink":"http://yoursite.com/2017/05/16/elasticsearch_cluster_docker/","excerpt":"","text":"Docker安装Elasticsearch集群一、通过docker下载最新的Elasticsearch镜像1sudo docker pull elasticsearch 1、测试运行elasticsearch12345sudo docker run -d -p 9200:9200 -p 9300:9300 --name=elasticsearch-test elasticsearch:latest 2、查看容器配置1sudo docker inspect elasticsearch-test 3、删除测试容器12sudo docker stop elasticsearch-testsudo docker rm elasticsearch-test 二、单节点安装创建集群名为my_cluster的集群(默认的集群名为elasticsearch) 1、安装节点123456sudo docker run -d --restart=always -p 9200:9200 -p 9300:9300 \\--name=elasticsearch-client \\--oom-kill-disable=true --memory-swappiness=1 \\-v /opt/elasticsearch/data:/usr/share/elasticsearch/data \\-v /opt/elasticsearch/logs:/usr/share/elasticsearch/logs \\elasticsearch:latest 2、节点配置12345678910111213141516cat &gt;elasticsearch.yml &lt;&lt;HEREcluster.name: my_clusternode.name: $&#123;HOSTNAME&#125;node.master: falsenode.data: falsepath.data: /usr/share/elasticsearch/datapath.logs: /usr/share/elasticsearch/logsbootstrap.mlockall: truenetwork.host: 0.0.0.0network.publish_host: 192.168.168.11transport.tcp.port: 9300http.port: 9200index.refresh_interval: 5sscript.inline: truescript.indexed: trueHERE 3、配置完成重启节点12sudo docker cp elasticsearch.yml elasticsearch-client:/usr/share/elasticsearch/config/elasticsearch.ymlsudo docker restart elasticsearch-client 直接将修改好的配置文件cp到容器对应位置后重启容器man docker-run –net=”bridge” Set the Network mode for the container ‘bridge’: create a network stack on the default Docker bridge ‘none’: no networking ‘container:’: reuse another container’s network stack ‘host’: use the Docker host network stack. Note: the host mode gives the container full access to local system services such as D-bus and is therefore considered insecure.说明:docker默认的网络模式为bridge,会自动为容器分配一个私有地址，如果是多台宿主机之间集群通信需要借助Consul,Etcd,Doozer等服务发现，自动注册组件来协同。请参看Docker集群之Swarm+Consul+Shipyard 必须通过network.publish_host: 192.168.168.11参数指定elasticsearch节点对外的监听地址,非常重要,不指定的话,集群节点间无法正常通信,报错如下[2016-06-21 05:50:19,123][INFO ][discovery.zen ] [consul-s2.example.com] failed to send join request to master [{consul-s1.example.com}{DeKixlVMS2yoynzX8Y-gdA}{172.17.0.1}{172.17.0.1:9300}{data=false, master=true}], reason [RemoteTransportException[[consul-s2.example.com][172.17.0.1:9300]最简单的，还可以网络直接设为host模式–net=host，直接借用宿主机的网络接口,换言之,不做网络层的layer同时可禁用OOM，还可根据宿主机内存来设置-m参数(默认为0，无限)限制容器内存大小[root@ela-client ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES762e4d21aaf8 elasticsearch:2.3.3 “/docker-entrypoint.s” 2 minutes ago Up 2 minutes elasticsearch-client[root@ela-client ~]# netstat -tunlp|grep javatcp 0 0 0.0.0.0:9200 0.0.0.0: LISTEN 18952/javatcp 0 0 0.0.0.0:9300 0.0.0.0: LISTEN 18952/java[root@ela-client ~]# ls /opt/elasticsearch/data logs 或者卷映射,个人认为卷映射更便于管理与备份 123456789101112131415161718192021222324252627mkdir -p /opt/elasticsearch/configcat &gt;/opt/elasticsearch/config/elasticsearch.yml &lt;&lt;HEREcluster.name: elasticsearch_clusternode.name: $&#123;HOSTNAME&#125;node.master: falsenode.data: falsepath.data: /usr/share/elasticsearch/datapath.logs: /usr/share/elasticsearch/logsbootstrap.mlockall: truenetwork.host: 0.0.0.0network.publish_host: 192.168.168.11transport.tcp.port: 9300http.port: 9200index.refresh_interval: 5sscript.inline: truescript.indexed: trueHEREdocker run -tid --restart=always \\ -p 9200:9200 \\ -p 9300:9300 \\ --oom-kill-disable=true \\ --memory-swappiness=1 \\ -v /opt/elasticsearch/data:/usr/share/elasticsearch/data \\ -v /opt/elasticsearch/logs:/usr/share/elasticsearch/logs \\ -v /opt/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ --name=elasticsearch-client \\ elasticsearch:latest 三、集群安装","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://yoursite.com/categories/Elasticsearch/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://yoursite.com/tags/Elasticsearch/"}]},{"title":"Redis 的一些理解","slug":"redis-concept","date":"2017-05-01T02:07:37.000Z","updated":"2017-05-13T04:58:43.944Z","comments":true,"path":"2017/05/01/redis-concept/","link":"","permalink":"http://yoursite.com/2017/05/01/redis-concept/","excerpt":"","text":"相信每一个工程师对redis并不陌生，通常可作为缓存,持久化Key-Value数据库,消息队列等解决方案。朕最近对这个也挺感兴趣的，所以就看看了，本文章主要三个部分：数据结构与对象，数据库实现（包括单机，集群，docker集群），使用场景。下面分别介绍。 第一部分 数据结构与对象第一章 数据结构地球人都知道redis有五种数据类型：字符串(string)，列表(list)，哈希(hash)，集合(set)，有序集合(zset)。我们可以用12127.0.0.1:30001&gt; type keystring 来获取key的数据类型，但其实这只是比较高层的数据类型，而非底层数据结构，那我们接下来学习一下redis的底层数据结构，redis主要包括了六大类数据结构字符串，链表，字典，跳跃表，整数集合，压缩列表。 1、字符串大家都知道redis是用C写的程序，我们知道C中字符串其实就是一个char数组以”\\0”结束便是一个字符串了，但redis类似于模仿Java Bean一样定义了一个数据结构。这就是redis的字符串神器SDS（一看名字就很高端，其实很简单）。12345struct sdshdr&#123; int len;#记录buf数组中已经使用字节的数量 int free;#记录buf数组中空闲字节的数量 char buf[];#和c一样保存字符串啦&#125;； 看出与C的不同了吧，它有什么好处呢？ 获取字符串长度变得so easy了。 因为空间容量是已知的，修改字符串就不会缓冲区溢出啦。 减少内存空间重分配的次数（这个策略是：a、初始设置string值是string的长度为len-1，为什么减一就不用解释了吧；b、然后修改字符串并且长度大于当前len需要扩展空间的时候就会进行空间预分配，这时如果len=1m那么新len = len + 1m + 1byte；c、如果修改字符串，当长度不需要那么长时，并不回收空间，而是增大free值。） 2、链表链表很简单，就是我们熟知的链表，先定义一个节点数据结构，再定义数据结构来对链表操作。 链表节点12345typedef struct listNode&#123; struct listNode *prev;#前置节点 struct listNode *next;#后置节点 void *value;#节点值&#125;listNode； 链表操作结构12345678typedef struct listNode&#123; listNode *head;#头节点 listNode *tail;#尾节点 unsigned long len;#链表节点数 void *(*dup)(void *ptr)#节点值复制函数 void (*free)(void *ptr);#节点值释放函数 int (*match)(void *ptr, void *key);#节点值对比函数&#125;listNode； 3、字典字典又叫符号表，关联数组，映射表。Redis的字典就是用哈希表实现的。一个哈希表可以有多个哈希表节点，但是每个哈希表节点就保存了字典中的一个键值对。下面看看哈希表的结构定义： 哈希表123456typedef struct dictht&#123; dictEntry **table;#哈希表数组 unsigned long size;#哈希表大小 unsigned long sizemask;#哈希表大小掩码，用于计算索引值 总是等于size-1 unsigned long used;#该哈希表中已有节点的数量&#125; 这里需要注意的是size与used的区别，size指的是table的大小，而used表示的是哈希表节点已有的数量(当used/size&gt;=1时，会触发重建哈希)，下面看看哈希表节点的数据结构：123456789typedef struct dictEntry&#123; void *key;#键 union&#123; void *val; uint64_t u64; int64_t s64; &#125; v;#值 struct dictEntry *next;#下一个哈希表节点，形成链表&#125; 字典123456typedef struct dict&#123; dictType *type;#类型特定函数 void *privdata;#私有数据 dictht ht[2];#哈希表 int rehashidx;#rehash索引 没有rehash时值为-1&#125; 这里重点是ht属性，有两个哈希表是指当rehash的时候会用第二个哈希表去为第一个重建哈希。而rehashidx记录的重建哈希的进度。 重建哈希为什么要重建哈希的，总的来说就是因为由于哈希节点越来越多，为了减少键冲突，或者键值对越来越少，不能造一个房子大的箱子就为了装一个鸡蛋吧。所以重建哈希。步骤如下： 为ht[1]分配空间，大小随操作而定 如果执行扩展操作，ht[1]的大小为第一个大于等于ht[0].used2的 2^n(例如：如果ht[0].used = 7，72=14，那么ht[1]的大小=16) 如果执行扩展操作，ht[1]的大小为第一个大于等于ht[0].used的 2^n(例如：如果ht[0].used = 7，那么ht[1]的大小=8) 然后将ht[0]全部复制到ht[1]上。 释放ht[0]，然后将ht[1]设置为ht[0]，并在ht[1]上创建了一个空白哈希表。 4、跳跃表Redis中只有两个地方用到跳跃表，一个是有序集合键，另一个是在集群节点中用作内部数据结构。123456789typedef struct zskiplistNode&#123; struct zskiplistNode *backward;#后退指针 double score;#分值 robj *obj;#成员对象 struct zskiplistLevel &#123; struct zskiplistNode *forward;#前进指针 unsigned int span;#跨度 &#125;level[];&#125;zskiplistNode; 5、整数集合整数集合是集合键的底层实现之一，当一个集合只有整数元素，并且集合元素数量不多时就会使用整数集合作为底层实现。12345typedef struct zskiplistNode&#123; uint32_t encoding;#编码方式 uint32_t length;#集合包含的元素数量 int8_t contents[];#保存元素的数组&#125;intset; 注意contents[]的属性声明int8_t但并不代表他就是保存int8_t类型的数组，它保存的类型由encoding决定，而encoding的值有三种值：INSET_ENC_INT16(类型是：int16_t),INSET_ENC_INT32(类型是：int32_t),INSET_ENC_INT16(类型是：int64_t), 整数集合的升级当我们每添加一个新的元素到整数集合里，并且新元素的类型要比整数集合现有所有元素的类型要长时，整数集合需要先进行升级，然后才能将新元素添加到整数集合里面。添加步骤： 根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间。 将底层数组现有所有的元素都转换为与新元素相同的类型，并将类型装换后的元素放置到正确的位置上，而且在放置元素的过程中需要维持底层数组的有序性不变。 将新元素添加到底层数组里面 注意：整数集合不支持降级，一旦对数组进行了升级，编码便会保持升级后的状态。 6、压缩列表压缩列表是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么Redis就会使用压缩列表来实现列表键。当一个哈希键只包含少量键值对，并且每个键值对的键和值要么就是小整数值，要么就是长度比较短的字符串，那么Redis就会使用压缩列表来实现哈希键。 压缩列表的结构 zlbytes zltail zllen entry1 entry2 … entryN zlend 压缩列表的组成成分详细说明 属性 类型 长度（字节） 用途 zlbytes uint32_t 4 压缩列表所占字节数，对压缩列表内存重分配或者计算zend的位置时使用 zltail uint32_t 4 记录压缩列表尾节点距离起始地址的字节数，即尾节点的位置 zllen uint16_t 2 节点数（最大值65535），当大于这个数的时候需要遍历压缩列表 entryX 列表节点 不定 压缩列表节点 zlend uint8_t 1 特殊值0XFF（255）标记列表末端 压缩列表的节点结构 前个字段长度 编码 内容 previous_entry_length encoding content previous_entry_length这个字段记录的前一个节点的长度，这个字段占用1个字节或者5个字节。当前一个节点的长度小于254个字节，本字段占用1个字节；当前一个节点的长度大于或等于254个字节，本字段占用5个字节.由于这种特性，修改一个节点数据会导致连锁更新，所有节点都需要重新分配内存空间。通过这个字段和压缩列表的zltail属性可以实现压缩列表的从表尾向表头遍历。 encoding这个字段记录了content属性所保存数据的类型以及长度 content节点值，可以是一个字节数组（字符串）或者整数 第二章 对象我们可以通过object encoding key命令查询对象的编码方式。还有大家要知道一个对象在底层是怎么存储的：12345typedef struct redisObject&#123; unsigned type:4;#类型 unsigned encoding:4;#编码 void *ptr;#指向具体的实现数据&#125;robj; 1、字符串对象字符串可以有三种编码方式int,embstr,raw当一个字符串对象是整数值，并且可以用long表示则用int的编码方式；当一个字符串长度小于或等于39字节则用embstr的编码方式；其他情况用raw编码方式。embstr相对于raw的优点是redisObject和sdshdr结构是连续的，内存一起分配也一起释放，但它是只读的，任何embstr的字符串修改后都变成了raw。 2、列表对象列表对象的编码可以是ziplist或者linkedlist。使用ziplist编码的条件是： 列表保存的所有字符串元素长度小于64字节 列表对象元素个数小于512个 3、哈希对象哈希对象的编码可以是ziplist和hashtable。当用ziplist作为底层实现时，每当有新的键值对加入哈希对象时，程序会先将键推入压缩列表表尾，再把值推入列表表尾。所以键值对总是挨在一起的。使用ziplist编码的条件是： 哈希保存的所有键和值字符串元素长度都小于64字节 哈希对象元素个数小于512个 4、集合对象集合对象的编码可以是intset和hashtable。使用intset编码的条件是： 集合保存的所有元素都是整数值 集合对象元素个数小于512个 当用hashtable保存集合对象时，哈希表的键保存集合元素，value都被设置为null。 5、有序集合对象有序集合对象的编码可以是ziplist和zskiplist。当用ziplist来保存有序集合对象时，每每都是第一个节点保存元素成员，第二个保存分数。并且在压缩列表内按照从小到大排序。当用zskiplist作为有序集合底层实现时，一个zset包含了一个skiplist和一个dict，如下：1234typedef struct zset&#123; skiplist *zsl; dict *dict;&#125;zset; 字典的作用是：字典的键保存了元素的成员，值保存了分值，这样用O(1)复杂度就可以获取元素的分值。使用ziplist编码的条件是： 有序集合保存的所有元素成员长度都小于64字节 有序集合对象元素个数小于128个 6、对象相关Redis在初始化服务的时候会创建一万个共享对象：0~9999这些对象不用重新创建对象的空转时长（通过lru属性计算）记录了对象最后一次被命令访问的时间，通过下面命令查看空转时长（当前时间减去lru时间计算得出）。1OBJECT IDLETIME key 第二部分 数据库实现第三章 过期时间与数据库持久化1、设置过期时间在Redis中有四种设置过期时间的方式 命令 单位 描述 EXPIRE 秒 设置生存时间（可以活多久） PEXPIRE 毫秒 设置生存时间（可以活多久） EXPIREAT 秒 过期时间戳 PEXPIREAT 毫秒 过期时间戳 TTL KEY 查看剩余时间 单位 秒 PRESISIT KEY 移除过期时间 其实事实上虽说有四个命令，但都是通过换算成PEXPIREAT实现的。redisDb结构的expires字典保存了数据库中所有键的过期时间，我们称这个为过期字典。 2、过期键删除策略Redis服务器采用的是惰性删除和定期删除。惰性删除：指的是程序读取键时，判定键有没有过期，过期则删除。定期删除：每隔一段时间，程序对数据库做一次检查，删除过期键。这里需要注意的是定期检查并不是全盘扫描，而是从一定数量的数据库中取出一定数量的随机键进行检查，并删除过期键。 3、生成RDB文件在执行SAVE或者BGSAVE命令时候程序会对数据库中的键进行检查，如果过期就不会保存到RDB文件中。 4、载入RDB文件主：载入RDB时，程序会对文件中保存的键进行检查，未过期的载入数据库。从：载入时不检查，所有都载入数据库。因为在进行主从同步的时候，从库数据会被清空，所以过期键载入对从库没有影响。 5、AOF生成aof文件时如果数据库某个键已过期但是没有被惰性删除或者定期删除，那么aof文件不会因为这个键已过期而产生任何影响，当被检查要删除的时候，程序会对aof文件追加一条del命令，显示标识已被删除。而aof重写会忽略已过期的键。 6、复制当服务器运行在复制模式下，从服务器的过期键删除动作由主服务器控制： 主在删除一个过期键的时候会显式的向所有从服务器发送一个DEL命令 从库执行客户端读命令时即使碰到过期键也不删除，而是继续返回过期键 从库只有接收到主库的del命令才会删除过期键。 7、数据库通知redis 2.8以后可以让客户端通过订阅数据库中键的变化，以及命令的执行情况：12127.0.0.1:6379 &gt; SUBSCRIBE __keyspace@0__:message #对0号库message键监听执行哪些命令127.0.0.1:6379 &gt; SUBSCRIBE __keyevent@0__:del #对0号库所有执行del操作的键 8、数据库持久化数据库持久化分为RDB和AOF两种方式 ： RDB就是通过Redis的ServerCron（间隔100毫秒）判断一次是否满足持久化条件，例如：save 900 1save 300 10save 60 10000900秒内数据库修改1次执行BGSAVE300秒内数据库修改10次执行BGSAVE60秒内数据库修改10000次执行BGSAVEredisServer会有dirty和lastsave，dirty记录了上次执行save或者bgsave之后数据库修改的次数，lastsave记录了上次持久化的时间，程序就是检查这两个参数是否达到持久化的条件。 AOF文件的写入与同步 appendsync选项的值 flushAppendOnlyFile函数的行为 alway 将aof_buf缓冲区所有内容写入并同步到aof everysec 将aof_buf缓冲区所有内容写入到aof，如果上次同步到现在超过1秒，再次对AOF文件进行同步 no 将aof_buf缓冲区所有内容写入到aof，但不同步，何时同步由操作系统决定 9、客户端对于每个与服务器连接的客户端，服务器都会为这些客户端建立相应的redis.h/redisClient结构（客户端状态），这个结构保存了当前客户端的状态信息，以及执行相关功能要用道德数据结构。输入缓冲区：客户端发送的命令请求；输出缓冲区：执行客户端命令的回复 第四章 集群1、复制Redis的复制包括同步和命令传播： 同步就是从服务器的数据库状态更新到主服务器的数据库状态。 命令传播的作用是主服务器数据库状态被修改，导致主从不一致，需要让主从重新一致。 旧版同步（SYNC）命令过时了不讲，因为存在缺陷：每次执行命令，从服务器都将让主服务器生成RDB文件，并全部读取完成数据库状态，然后再从命令缓冲区读取命令，让主从完成一致。不用说这就像你盖房子，人家让你修改一下你就把房子推了重新盖，极其消耗不必要的资源。新版同步（PSYNC）命令，具有完整同步和部分同步两种模式： 完整同步用于初次同步，和SYNC一样读取全部RDB文件，以及读取命令缓冲区的命令完成主从一致。 部分同步用于当从服务器断线后重新连接，符合条件（条件后面说）的话，主服务器将主从连接断开期间主服务器执行的写命令发送给从服务器，从服务器执行命令完成主从一致。 部分同步的条件： 主从服务器各自的复制偏移量。 主服务器的复制积压缓冲区。 服务器的运行id。 复制偏移量：是指执行复制的双方都会维护一个复制偏移量，主服务器向从服务器传播N个字节的数据时，便将自己的偏移量加N；从服务器每次从主收到N字节的数据时就将自己的偏移量加N。（如果主从一致，复制偏移量是一样的）复制积压缓冲区：是指主服务器会有一个固定长度的一个队列，如果从服务器执行PSYNC命令时会将自己的复制偏移量offset发送给主服务器，主服务器根据这个决定执行哪种同步方式： 如果offset偏移量之后的数据仍在复制缓冲区，那么主服务器对从服务器执行部分同步； 如果offset偏移量之后的数据不在复制缓冲区，那么主服务器对从服务器执行完整同步。 服务器运行id：不论主从都有自己的运行id，在服务器启动时自动生成，由40个16进制字符组成，当主从初次同步时，主服务器会将自己的运行id传给从服务器保存起来，从服务器断线重连时，从服务器会将自己保存的运行id传给主服务器，主服务器收到id判断是否和自己的运行id一致，如果一致便可以执行部分同步，反之说明从库现在连接的主库不是之前的主库，需要进行完整同步。 复制的步骤： 设置主服务器的地址端口 eg： slaveof 127.0.0.1 6379 建立套接字连接 从发送PING命令，主回复PONG命令 身份验证（需要配置：masterauth选项） 从向主发送监听端口信息 eg： REPLCONF listening-port 12345 同步 命令传播 心跳检测：在命令传播阶段，从服务器每秒一次向主发送命令：REPLCONF ACK ##就是发送复制偏移量。作用有三个： 检查主从网络连接状况（如果lag大于1秒说明主从连接有故障）； 辅助实现min-slaves配置选项 123min-slaves-to-write 3min-slaves-max-lag 10#指：当从服务器少于3个，或者3个服务器的延迟（lag值 可以通过‘info replication’命令获取）主服务器将拒绝写命令。 检测命令丢失（如果主传给从的命令在半路丢失，那么重服务器向主发送心态检测携带了复制偏移量，主会发觉从服务器的复制偏移量少于自己的，主就会将复制缓冲区中找到从缺少的数据，然后重新发给从）。 2、Sentinel3、集群","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"},{"name":"SDS","slug":"SDS","permalink":"http://yoursite.com/tags/SDS/"}]},{"title":"配置SSH连接github","slug":"setSSH","date":"2017-04-12T02:07:37.000Z","updated":"2017-05-13T04:59:08.515Z","comments":true,"path":"2017/04/12/setSSH/","link":"","permalink":"http://yoursite.com/2017/04/12/setSSH/","excerpt":"","text":"配置本机的ssh key通过ssh keys就可以将本地的项目与Github关联起来 1. 检查本机ssh keycd ~/.ssh提示：没使用过Git就会显示：No such file or directory 2. 生成新的ssh keys1$ ssh-keygen -t rsa -C \"邮件地址@youremail.com\" Generating public/private rsa key pair.Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&lt;回车就好&gt;注意：-C为大写的C接下来会让你输入密码Enter passphrase (empty for no passphrase):&lt;输入加密串&gt;Enter same passphrase again:&lt;再次输入加密串&gt;注意：输入密码时是不会显示密码的，依次输入就好了如果显示为下界面，就设置ssh key成功了 3. 添加ssh key到Github 搜索本机上的id_rsa.pub文件。或在C:\\Documents and Settings\\Administrator.ssh\\id_rsa.pub路径下找到该文件。以记事本打开，复制其中的内容 进入自己的Github，右上角齿轮setting—左边列表SSH keys—Add SSH key。将内容复制到文本框（不会取title名字）。注意：这时Github会给你的邮箱发送一封邮件，打开邮件确认下就好了。 4. 测试ssh -T git@github.com如果是以下反馈 The authenticity of host ‘github.com (207.97.227.239)’ can’t be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)?输入yes Hi yourusername! You’ve successfully authenticated, but GitHub does not provide shell access.这时候说明能够通过SSH链接到你的Github了，接下来完善一下你的个人信息。Git会根据用户的名字和邮箱来记录提交。GitHub也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成你自己的，名字必须是你的真名，而不是GitHub的昵称。 5. 配置用户12git config --global user.name \"Tim\"#用户名git config --global user.email \"tim@gmail.com\"#填写自己的邮箱","categories":[{"name":"SSH","slug":"SSH","permalink":"http://yoursite.com/categories/SSH/"}],"tags":[{"name":"SSH","slug":"SSH","permalink":"http://yoursite.com/tags/SSH/"},{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]},{"title":"使用Hexo创建个人的博客","slug":"hello-world","date":"2017-04-10T02:07:37.000Z","updated":"2017-05-13T04:55:57.605Z","comments":true,"path":"2017/04/10/hello-world/","link":"","permalink":"http://yoursite.com/2017/04/10/hello-world/","excerpt":"","text":"这里讲的是git+hexo+github创建个人博客，hexo是一个基于node的博客框架，当然如果另外两个东西不知道是啥的话也就没有必要继续下去了。 1、预备工作 注册github账号 安装git 安装node 2、好啦接下来可以安装Hexo了1$ npm install -g hexo 3、创建博客根目录1234567$ mkdir hexo$ cd hexo$ hexo init #该命令会将hexo所需文件自动下载到hexo文件夹下。$ npm install #安装依赖包#本地运行$ hexo generate$ hexo server 输入完以上命令打开浏览器输入网址localhost:4000查看，运行显示了相关页面说明成功。当前网站建立在本地而已。 4、配置ssh连接github（具体参考配置ssh连接github）5、使用Hexo克隆主题123hexo cleanhexo ghexo s 自己使用的是bluelake主题，比较喜欢，以这款主题为例。git@github.com:chaooo/hexo-theme-BlueLake.git 克隆主题1git clone git@github.com:chaooo/hexo-theme-BlueLake.git themes/BlueLake 配置修改hexo根目录下的 _config.yml ： theme: BlueLake 更新cd themes/BlueLakegit pull 6、部署博客部署Github前需要配置_config.yml文件1234deploy: type: github repository: http://github.com/username/username.github.io.git branch: master username为你的github用户名注意：type:空格github。都要使用空格，自己遇到过这个问题，结果怎么都上传不上去，所以提醒下。 上传123hexo cleanhexo ghexo d 会让你输入用户名和密码，依次输入就好。 本地查看12hexo ghexo s 浏览器输入localhost:4000，查看主题是否成功。 7、给博客绑定域名 项目添加域名 12345$ cd hexo/public$ echo www.xxx.com &gt; CNAME# 重新发布$ hexo g$ hexo d DNS设置 1234注册DNSPOD，添加域名192.30.252.153192.30.252.154以上为github提供的ip 等待DNS刷新可能需要等待一段时间。 8、写文章并发布路径hexo\\source_posts下新建文件就可以了 XXX.md使用Markdown语法进行书写简书Markdown语法指南注意：文档最上面写 Q&amp;A1、搭建 hexo，在执行 hexo deploy 后,出现 error deployer not found:github 的错误 npm install hexo-deployer-git –save 改了之后执行，然后再部署试试","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/categories/Hexo/"}],"tags":[{"name":"node","slug":"node","permalink":"http://yoursite.com/tags/node/"},{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"},{"name":"npm","slug":"npm","permalink":"http://yoursite.com/tags/npm/"}]}]}