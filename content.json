{"meta":{"title":"Leo Dominic","subtitle":"愿我出走半生，归来仍是少年","description":null,"author":"Leo Dominic","url":"http://yoursite.com"},"pages":[{"title":"categories","date":"2017-05-13T03:13:13.733Z","updated":"2017-05-13T03:13:13.733Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-05-13T03:12:46.996Z","updated":"2017-05-13T03:12:46.996Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"about me","date":"2017-04-11T15:41:37.000Z","updated":"2017-05-13T05:03:54.884Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"The Square Root of Three I fear that I will always be A lonely number like root three A three is all that's good and right Why must my three keep out of sight Beneath a vicious square-root sign? I wish instead I were a nine For nine could thwart this evil trick With just some quick arithmetic I know I'll never see the sun As 1.7321 Such is my reality A sad irrationality When,hark, just what is this I see? Another square root of a three Has quietly come waltzing by Together now we multiply To form a number we prefer Rejoicing as an integer We break free from our mortal bonds And with a wave of magic wands Our square-root signs become unglued And love for me has been renewed"}],"posts":[{"title":"Docker安装Elasticsearch集群","slug":"elasticsearch_cluster_docker","date":"2017-05-16T02:07:37.000Z","updated":"2017-05-16T15:22:03.514Z","comments":true,"path":"2017/05/16/elasticsearch_cluster_docker/","link":"","permalink":"http://yoursite.com/2017/05/16/elasticsearch_cluster_docker/","excerpt":"","text":"Docker安装Elasticsearch集群一、通过docker下载最新的Elasticsearch镜像1sudo docker pull elasticsearch 1、测试运行elasticsearch12345sudo docker run -d -p 9200:9200 -p 9300:9300 --name=elasticsearch-test elasticsearch:latest 2、查看容器配置1sudo docker inspect elasticsearch-test 3、删除测试容器12sudo docker stop elasticsearch-testsudo docker rm elasticsearch-test 二、单节点安装创建集群名为my_cluster的集群(默认的集群名为elasticsearch) 1、安装节点123456sudo docker run -d --restart=always -p 9200:9200 -p 9300:9300 \\--name=elasticsearch-client \\--oom-kill-disable=true --memory-swappiness=1 \\-v /opt/elasticsearch/data:/usr/share/elasticsearch/data \\-v /opt/elasticsearch/logs:/usr/share/elasticsearch/logs \\elasticsearch:latest 2、节点配置12345678910111213141516cat &gt;elasticsearch.yml &lt;&lt;HEREcluster.name: my_clusternode.name: $&#123;HOSTNAME&#125;node.master: falsenode.data: falsepath.data: /usr/share/elasticsearch/datapath.logs: /usr/share/elasticsearch/logsbootstrap.mlockall: truenetwork.host: 0.0.0.0network.publish_host: 192.168.168.11transport.tcp.port: 9300http.port: 9200index.refresh_interval: 5sscript.inline: truescript.indexed: trueHERE 3、配置完成重启节点12sudo docker cp elasticsearch.yml elasticsearch-client:/usr/share/elasticsearch/config/elasticsearch.ymlsudo docker restart elasticsearch-client 直接将修改好的配置文件cp到容器对应位置后重启容器man docker-run –net=”bridge” Set the Network mode for the container ‘bridge’: create a network stack on the default Docker bridge ‘none’: no networking ‘container:’: reuse another container’s network stack ‘host’: use the Docker host network stack. Note: the host mode gives the container full access to local system services such as D-bus and is therefore considered insecure.说明:docker默认的网络模式为bridge,会自动为容器分配一个私有地址，如果是多台宿主机之间集群通信需要借助Consul,Etcd,Doozer等服务发现，自动注册组件来协同。请参看Docker集群之Swarm+Consul+Shipyard 必须通过network.publish_host: 192.168.168.11参数指定elasticsearch节点对外的监听地址,非常重要,不指定的话,集群节点间无法正常通信,报错如下[2016-06-21 05:50:19,123][INFO ][discovery.zen ] [consul-s2.example.com] failed to send join request to master [{consul-s1.example.com}{DeKixlVMS2yoynzX8Y-gdA}{172.17.0.1}{172.17.0.1:9300}{data=false, master=true}], reason [RemoteTransportException[[consul-s2.example.com][172.17.0.1:9300]最简单的，还可以网络直接设为host模式–net=host，直接借用宿主机的网络接口,换言之,不做网络层的layer同时可禁用OOM，还可根据宿主机内存来设置-m参数(默认为0，无限)限制容器内存大小[root@ela-client ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES762e4d21aaf8 elasticsearch:2.3.3 “/docker-entrypoint.s” 2 minutes ago Up 2 minutes elasticsearch-client[root@ela-client ~]# netstat -tunlp|grep javatcp 0 0 0.0.0.0:9200 0.0.0.0: LISTEN 18952/javatcp 0 0 0.0.0.0:9300 0.0.0.0: LISTEN 18952/java[root@ela-client ~]# ls /opt/elasticsearch/data logs 或者卷映射,个人认为卷映射更便于管理与备份 123456789101112131415161718192021222324252627mkdir -p /opt/elasticsearch/configcat &gt;/opt/elasticsearch/config/elasticsearch.yml &lt;&lt;HEREcluster.name: elasticsearch_clusternode.name: $&#123;HOSTNAME&#125;node.master: falsenode.data: falsepath.data: /usr/share/elasticsearch/datapath.logs: /usr/share/elasticsearch/logsbootstrap.mlockall: truenetwork.host: 0.0.0.0network.publish_host: 192.168.168.11transport.tcp.port: 9300http.port: 9200index.refresh_interval: 5sscript.inline: truescript.indexed: trueHEREdocker run -tid --restart=always \\ -p 9200:9200 \\ -p 9300:9300 \\ --oom-kill-disable=true \\ --memory-swappiness=1 \\ -v /opt/elasticsearch/data:/usr/share/elasticsearch/data \\ -v /opt/elasticsearch/logs:/usr/share/elasticsearch/logs \\ -v /opt/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ --name=elasticsearch-client \\ elasticsearch:latest 三、集群安装","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://yoursite.com/categories/Elasticsearch/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://yoursite.com/tags/Elasticsearch/"}]},{"title":"Redis 的一些理解","slug":"redis-concept","date":"2017-05-01T02:07:37.000Z","updated":"2017-05-13T04:58:43.944Z","comments":true,"path":"2017/05/01/redis-concept/","link":"","permalink":"http://yoursite.com/2017/05/01/redis-concept/","excerpt":"","text":"相信每一个工程师对redis并不陌生，通常可作为缓存,持久化Key-Value数据库,消息队列等解决方案。朕最近对这个也挺感兴趣的，所以就看看了，本文章主要三个部分：数据结构与对象，数据库实现（包括单机，集群，docker集群），使用场景。下面分别介绍。 第一部分 数据结构与对象第一章 数据结构地球人都知道redis有五种数据类型：字符串(string)，列表(list)，哈希(hash)，集合(set)，有序集合(zset)。我们可以用12127.0.0.1:30001&gt; type keystring 来获取key的数据类型，但其实这只是比较高层的数据类型，而非底层数据结构，那我们接下来学习一下redis的底层数据结构，redis主要包括了六大类数据结构字符串，链表，字典，跳跃表，整数集合，压缩列表。 1、字符串大家都知道redis是用C写的程序，我们知道C中字符串其实就是一个char数组以”\\0”结束便是一个字符串了，但redis类似于模仿Java Bean一样定义了一个数据结构。这就是redis的字符串神器SDS（一看名字就很高端，其实很简单）。12345struct sdshdr&#123; int len;#记录buf数组中已经使用字节的数量 int free;#记录buf数组中空闲字节的数量 char buf[];#和c一样保存字符串啦&#125;； 看出与C的不同了吧，它有什么好处呢？ 获取字符串长度变得so easy了。 因为空间容量是已知的，修改字符串就不会缓冲区溢出啦。 减少内存空间重分配的次数（这个策略是：a、初始设置string值是string的长度为len-1，为什么减一就不用解释了吧；b、然后修改字符串并且长度大于当前len需要扩展空间的时候就会进行空间预分配，这时如果len=1m那么新len = len + 1m + 1byte；c、如果修改字符串，当长度不需要那么长时，并不回收空间，而是增大free值。） 2、链表链表很简单，就是我们熟知的链表，先定义一个节点数据结构，再定义数据结构来对链表操作。 链表节点12345typedef struct listNode&#123; struct listNode *prev;#前置节点 struct listNode *next;#后置节点 void *value;#节点值&#125;listNode； 链表操作结构12345678typedef struct listNode&#123; listNode *head;#头节点 listNode *tail;#尾节点 unsigned long len;#链表节点数 void *(*dup)(void *ptr)#节点值复制函数 void (*free)(void *ptr);#节点值释放函数 int (*match)(void *ptr, void *key);#节点值对比函数&#125;listNode； 3、字典字典又叫符号表，关联数组，映射表。Redis的字典就是用哈希表实现的。一个哈希表可以有多个哈希表节点，但是每个哈希表节点就保存了字典中的一个键值对。下面看看哈希表的结构定义： 哈希表123456typedef struct dictht&#123; dictEntry **table;#哈希表数组 unsigned long size;#哈希表大小 unsigned long sizemask;#哈希表大小掩码，用于计算索引值 总是等于size-1 unsigned long used;#该哈希表中已有节点的数量&#125; 这里需要注意的是size与used的区别，size指的是table的大小，而used表示的是哈希表节点已有的数量(当used/size&gt;=1时，会触发重建哈希)，下面看看哈希表节点的数据结构：123456789typedef struct dictEntry&#123; void *key;#键 union&#123; void *val; uint64_t u64; int64_t s64; &#125; v;#值 struct dictEntry *next;#下一个哈希表节点，形成链表&#125; 字典123456typedef struct dict&#123; dictType *type;#类型特定函数 void *privdata;#私有数据 dictht ht[2];#哈希表 int rehashidx;#rehash索引 没有rehash时值为-1&#125; 这里重点是ht属性，有两个哈希表是指当rehash的时候会用第二个哈希表去为第一个重建哈希。而rehashidx记录的重建哈希的进度。 重建哈希为什么要重建哈希的，总的来说就是因为由于哈希节点越来越多，为了减少键冲突，或者键值对越来越少，不能造一个房子大的箱子就为了装一个鸡蛋吧。所以重建哈希。步骤如下： 为ht[1]分配空间，大小随操作而定 如果执行扩展操作，ht[1]的大小为第一个大于等于ht[0].used2的 2^n(例如：如果ht[0].used = 7，72=14，那么ht[1]的大小=16) 如果执行扩展操作，ht[1]的大小为第一个大于等于ht[0].used的 2^n(例如：如果ht[0].used = 7，那么ht[1]的大小=8) 然后将ht[0]全部复制到ht[1]上。 释放ht[0]，然后将ht[1]设置为ht[0]，并在ht[1]上创建了一个空白哈希表。 4、跳跃表Redis中只有两个地方用到跳跃表，一个是有序集合键，另一个是在集群节点中用作内部数据结构。123456789typedef struct zskiplistNode&#123; struct zskiplistNode *backward;#后退指针 double score;#分值 robj *obj;#成员对象 struct zskiplistLevel &#123; struct zskiplistNode *forward;#前进指针 unsigned int span;#跨度 &#125;level[];&#125;zskiplistNode; 5、整数集合整数集合是集合键的底层实现之一，当一个集合只有整数元素，并且集合元素数量不多时就会使用整数集合作为底层实现。12345typedef struct zskiplistNode&#123; uint32_t encoding;#编码方式 uint32_t length;#集合包含的元素数量 int8_t contents[];#保存元素的数组&#125;intset; 注意contents[]的属性声明int8_t但并不代表他就是保存int8_t类型的数组，它保存的类型由encoding决定，而encoding的值有三种值：INSET_ENC_INT16(类型是：int16_t),INSET_ENC_INT32(类型是：int32_t),INSET_ENC_INT16(类型是：int64_t), 整数集合的升级当我们每添加一个新的元素到整数集合里，并且新元素的类型要比整数集合现有所有元素的类型要长时，整数集合需要先进行升级，然后才能将新元素添加到整数集合里面。添加步骤： 根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间。 将底层数组现有所有的元素都转换为与新元素相同的类型，并将类型装换后的元素放置到正确的位置上，而且在放置元素的过程中需要维持底层数组的有序性不变。 将新元素添加到底层数组里面 注意：整数集合不支持降级，一旦对数组进行了升级，编码便会保持升级后的状态。 6、压缩列表压缩列表是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么Redis就会使用压缩列表来实现列表键。当一个哈希键只包含少量键值对，并且每个键值对的键和值要么就是小整数值，要么就是长度比较短的字符串，那么Redis就会使用压缩列表来实现哈希键。 压缩列表的结构 zlbytes zltail zllen entry1 entry2 … entryN zlend 压缩列表的组成成分详细说明 属性 类型 长度（字节） 用途 zlbytes uint32_t 4 压缩列表所占字节数，对压缩列表内存重分配或者计算zend的位置时使用 zltail uint32_t 4 记录压缩列表尾节点距离起始地址的字节数，即尾节点的位置 zllen uint16_t 2 节点数（最大值65535），当大于这个数的时候需要遍历压缩列表 entryX 列表节点 不定 压缩列表节点 zlend uint8_t 1 特殊值0XFF（255）标记列表末端 压缩列表的节点结构 前个字段长度 编码 内容 previous_entry_length encoding content previous_entry_length这个字段记录的前一个节点的长度，这个字段占用1个字节或者5个字节。当前一个节点的长度小于254个字节，本字段占用1个字节；当前一个节点的长度大于或等于254个字节，本字段占用5个字节.由于这种特性，修改一个节点数据会导致连锁更新，所有节点都需要重新分配内存空间。通过这个字段和压缩列表的zltail属性可以实现压缩列表的从表尾向表头遍历。 encoding这个字段记录了content属性所保存数据的类型以及长度 content节点值，可以是一个字节数组（字符串）或者整数 第二章 对象我们可以通过object encoding key命令查询对象的编码方式。还有大家要知道一个对象在底层是怎么存储的：12345typedef struct redisObject&#123; unsigned type:4;#类型 unsigned encoding:4;#编码 void *ptr;#指向具体的实现数据&#125;robj; 1、字符串对象字符串可以有三种编码方式int,embstr,raw当一个字符串对象是整数值，并且可以用long表示则用int的编码方式；当一个字符串长度小于或等于39字节则用embstr的编码方式；其他情况用raw编码方式。embstr相对于raw的优点是redisObject和sdshdr结构是连续的，内存一起分配也一起释放，但它是只读的，任何embstr的字符串修改后都变成了raw。 2、列表对象列表对象的编码可以是ziplist或者linkedlist。使用ziplist编码的条件是： 列表保存的所有字符串元素长度小于64字节 列表对象元素个数小于512个 3、哈希对象哈希对象的编码可以是ziplist和hashtable。当用ziplist作为底层实现时，每当有新的键值对加入哈希对象时，程序会先将键推入压缩列表表尾，再把值推入列表表尾。所以键值对总是挨在一起的。使用ziplist编码的条件是： 哈希保存的所有键和值字符串元素长度都小于64字节 哈希对象元素个数小于512个 4、集合对象集合对象的编码可以是intset和hashtable。使用intset编码的条件是： 集合保存的所有元素都是整数值 集合对象元素个数小于512个 当用hashtable保存集合对象时，哈希表的键保存集合元素，value都被设置为null。 5、有序集合对象有序集合对象的编码可以是ziplist和zskiplist。当用ziplist来保存有序集合对象时，每每都是第一个节点保存元素成员，第二个保存分数。并且在压缩列表内按照从小到大排序。当用zskiplist作为有序集合底层实现时，一个zset包含了一个skiplist和一个dict，如下：1234typedef struct zset&#123; skiplist *zsl; dict *dict;&#125;zset; 字典的作用是：字典的键保存了元素的成员，值保存了分值，这样用O(1)复杂度就可以获取元素的分值。使用ziplist编码的条件是： 有序集合保存的所有元素成员长度都小于64字节 有序集合对象元素个数小于128个 6、对象相关Redis在初始化服务的时候会创建一万个共享对象：0~9999这些对象不用重新创建对象的空转时长（通过lru属性计算）记录了对象最后一次被命令访问的时间，通过下面命令查看空转时长（当前时间减去lru时间计算得出）。1OBJECT IDLETIME key 第二部分 数据库实现第三章 过期时间与数据库持久化1、设置过期时间在Redis中有四种设置过期时间的方式 命令 单位 描述 EXPIRE 秒 设置生存时间（可以活多久） PEXPIRE 毫秒 设置生存时间（可以活多久） EXPIREAT 秒 过期时间戳 PEXPIREAT 毫秒 过期时间戳 TTL KEY 查看剩余时间 单位 秒 PRESISIT KEY 移除过期时间 其实事实上虽说有四个命令，但都是通过换算成PEXPIREAT实现的。redisDb结构的expires字典保存了数据库中所有键的过期时间，我们称这个为过期字典。 2、过期键删除策略Redis服务器采用的是惰性删除和定期删除。惰性删除：指的是程序读取键时，判定键有没有过期，过期则删除。定期删除：每隔一段时间，程序对数据库做一次检查，删除过期键。这里需要注意的是定期检查并不是全盘扫描，而是从一定数量的数据库中取出一定数量的随机键进行检查，并删除过期键。 3、生成RDB文件在执行SAVE或者BGSAVE命令时候程序会对数据库中的键进行检查，如果过期就不会保存到RDB文件中。 4、载入RDB文件主：载入RDB时，程序会对文件中保存的键进行检查，未过期的载入数据库。从：载入时不检查，所有都载入数据库。因为在进行主从同步的时候，从库数据会被清空，所以过期键载入对从库没有影响。 5、AOF生成aof文件时如果数据库某个键已过期但是没有被惰性删除或者定期删除，那么aof文件不会因为这个键已过期而产生任何影响，当被检查要删除的时候，程序会对aof文件追加一条del命令，显示标识已被删除。而aof重写会忽略已过期的键。 6、复制当服务器运行在复制模式下，从服务器的过期键删除动作由主服务器控制： 主在删除一个过期键的时候会显式的向所有从服务器发送一个DEL命令 从库执行客户端读命令时即使碰到过期键也不删除，而是继续返回过期键 从库只有接收到主库的del命令才会删除过期键。 7、数据库通知redis 2.8以后可以让客户端通过订阅数据库中键的变化，以及命令的执行情况：12127.0.0.1:6379 &gt; SUBSCRIBE __keyspace@0__:message #对0号库message键监听执行哪些命令127.0.0.1:6379 &gt; SUBSCRIBE __keyevent@0__:del #对0号库所有执行del操作的键 8、数据库持久化数据库持久化分为RDB和AOF两种方式 ： RDB就是通过Redis的ServerCron（间隔100毫秒）判断一次是否满足持久化条件，例如：save 900 1save 300 10save 60 10000900秒内数据库修改1次执行BGSAVE300秒内数据库修改10次执行BGSAVE60秒内数据库修改10000次执行BGSAVEredisServer会有dirty和lastsave，dirty记录了上次执行save或者bgsave之后数据库修改的次数，lastsave记录了上次持久化的时间，程序就是检查这两个参数是否达到持久化的条件。 AOF文件的写入与同步 appendsync选项的值 flushAppendOnlyFile函数的行为 alway 将aof_buf缓冲区所有内容写入并同步到aof everysec 将aof_buf缓冲区所有内容写入到aof，如果上次同步到现在超过1秒，再次对AOF文件进行同步 no 将aof_buf缓冲区所有内容写入到aof，但不同步，何时同步由操作系统决定 9、客户端对于每个与服务器连接的客户端，服务器都会为这些客户端建立相应的redis.h/redisClient结构（客户端状态），这个结构保存了当前客户端的状态信息，以及执行相关功能要用道德数据结构。输入缓冲区：客户端发送的命令请求；输出缓冲区：执行客户端命令的回复 第四章 集群1、复制Redis的复制包括同步和命令传播： 同步就是从服务器的数据库状态更新到主服务器的数据库状态。 命令传播的作用是主服务器数据库状态被修改，导致主从不一致，需要让主从重新一致。 旧版同步（SYNC）命令过时了不讲，因为存在缺陷：每次执行命令，从服务器都将让主服务器生成RDB文件，并全部读取完成数据库状态，然后再从命令缓冲区读取命令，让主从完成一致。不用说这就像你盖房子，人家让你修改一下你就把房子推了重新盖，极其消耗不必要的资源。新版同步（PSYNC）命令，具有完整同步和部分同步两种模式： 完整同步用于初次同步，和SYNC一样读取全部RDB文件，以及读取命令缓冲区的命令完成主从一致。 部分同步用于当从服务器断线后重新连接，符合条件（条件后面说）的话，主服务器将主从连接断开期间主服务器执行的写命令发送给从服务器，从服务器执行命令完成主从一致。 部分同步的条件： 主从服务器各自的复制偏移量。 主服务器的复制积压缓冲区。 服务器的运行id。 复制偏移量：是指执行复制的双方都会维护一个复制偏移量，主服务器向从服务器传播N个字节的数据时，便将自己的偏移量加N；从服务器每次从主收到N字节的数据时就将自己的偏移量加N。（如果主从一致，复制偏移量是一样的）复制积压缓冲区：是指主服务器会有一个固定长度的一个队列，如果从服务器执行PSYNC命令时会将自己的复制偏移量offset发送给主服务器，主服务器根据这个决定执行哪种同步方式： 如果offset偏移量之后的数据仍在复制缓冲区，那么主服务器对从服务器执行部分同步； 如果offset偏移量之后的数据不在复制缓冲区，那么主服务器对从服务器执行完整同步。 服务器运行id：不论主从都有自己的运行id，在服务器启动时自动生成，由40个16进制字符组成，当主从初次同步时，主服务器会将自己的运行id传给从服务器保存起来，从服务器断线重连时，从服务器会将自己保存的运行id传给主服务器，主服务器收到id判断是否和自己的运行id一致，如果一致便可以执行部分同步，反之说明从库现在连接的主库不是之前的主库，需要进行完整同步。 复制的步骤： 设置主服务器的地址端口 eg： slaveof 127.0.0.1 6379 建立套接字连接 从发送PING命令，主回复PONG命令 身份验证（需要配置：masterauth选项） 从向主发送监听端口信息 eg： REPLCONF listening-port 12345 同步 命令传播 心跳检测：在命令传播阶段，从服务器每秒一次向主发送命令：REPLCONF ACK ##就是发送复制偏移量。作用有三个： 检查主从网络连接状况（如果lag大于1秒说明主从连接有故障）； 辅助实现min-slaves配置选项 123min-slaves-to-write 3min-slaves-max-lag 10#指：当从服务器少于3个，或者3个服务器的延迟（lag值 可以通过‘info replication’命令获取）主服务器将拒绝写命令。 检测命令丢失（如果主传给从的命令在半路丢失，那么重服务器向主发送心态检测携带了复制偏移量，主会发觉从服务器的复制偏移量少于自己的，主就会将复制缓冲区中找到从缺少的数据，然后重新发给从）。 2、Sentinel3、集群","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"},{"name":"SDS","slug":"SDS","permalink":"http://yoursite.com/tags/SDS/"}]},{"title":"配置SSH连接github","slug":"setSSH","date":"2017-04-12T02:07:37.000Z","updated":"2017-05-13T04:59:08.515Z","comments":true,"path":"2017/04/12/setSSH/","link":"","permalink":"http://yoursite.com/2017/04/12/setSSH/","excerpt":"","text":"配置本机的ssh key通过ssh keys就可以将本地的项目与Github关联起来 1. 检查本机ssh keycd ~/.ssh提示：没使用过Git就会显示：No such file or directory 2. 生成新的ssh keys1$ ssh-keygen -t rsa -C \"邮件地址@youremail.com\" Generating public/private rsa key pair.Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&lt;回车就好&gt;注意：-C为大写的C接下来会让你输入密码Enter passphrase (empty for no passphrase):&lt;输入加密串&gt;Enter same passphrase again:&lt;再次输入加密串&gt;注意：输入密码时是不会显示密码的，依次输入就好了如果显示为下界面，就设置ssh key成功了 3. 添加ssh key到Github 搜索本机上的id_rsa.pub文件。或在C:\\Documents and Settings\\Administrator.ssh\\id_rsa.pub路径下找到该文件。以记事本打开，复制其中的内容 进入自己的Github，右上角齿轮setting—左边列表SSH keys—Add SSH key。将内容复制到文本框（不会取title名字）。注意：这时Github会给你的邮箱发送一封邮件，打开邮件确认下就好了。 4. 测试ssh -T git@github.com如果是以下反馈 The authenticity of host ‘github.com (207.97.227.239)’ can’t be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)?输入yes Hi yourusername! You’ve successfully authenticated, but GitHub does not provide shell access.这时候说明能够通过SSH链接到你的Github了，接下来完善一下你的个人信息。Git会根据用户的名字和邮箱来记录提交。GitHub也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成你自己的，名字必须是你的真名，而不是GitHub的昵称。 5. 配置用户12git config --global user.name \"Tim\"#用户名git config --global user.email \"tim@gmail.com\"#填写自己的邮箱","categories":[{"name":"SSH","slug":"SSH","permalink":"http://yoursite.com/categories/SSH/"}],"tags":[{"name":"SSH","slug":"SSH","permalink":"http://yoursite.com/tags/SSH/"},{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]},{"title":"使用Hexo创建个人的博客","slug":"hello-world","date":"2017-04-10T02:07:37.000Z","updated":"2017-05-13T04:55:57.605Z","comments":true,"path":"2017/04/10/hello-world/","link":"","permalink":"http://yoursite.com/2017/04/10/hello-world/","excerpt":"","text":"这里讲的是git+hexo+github创建个人博客，hexo是一个基于node的博客框架，当然如果另外两个东西不知道是啥的话也就没有必要继续下去了。 1、预备工作 注册github账号 安装git 安装node 2、好啦接下来可以安装Hexo了1$ npm install -g hexo 3、创建博客根目录1234567$ mkdir hexo$ cd hexo$ hexo init #该命令会将hexo所需文件自动下载到hexo文件夹下。$ npm install #安装依赖包#本地运行$ hexo generate$ hexo server 输入完以上命令打开浏览器输入网址localhost:4000查看，运行显示了相关页面说明成功。当前网站建立在本地而已。 4、配置ssh连接github（具体参考配置ssh连接github）5、使用Hexo克隆主题123hexo cleanhexo ghexo s 自己使用的是bluelake主题，比较喜欢，以这款主题为例。git@github.com:chaooo/hexo-theme-BlueLake.git 克隆主题1git clone git@github.com:chaooo/hexo-theme-BlueLake.git themes/BlueLake 配置修改hexo根目录下的 _config.yml ： theme: BlueLake 更新cd themes/BlueLakegit pull 6、部署博客部署Github前需要配置_config.yml文件1234deploy: type: github repository: http://github.com/username/username.github.io.git branch: master username为你的github用户名注意：type:空格github。都要使用空格，自己遇到过这个问题，结果怎么都上传不上去，所以提醒下。 上传123hexo cleanhexo ghexo d 会让你输入用户名和密码，依次输入就好。 本地查看12hexo ghexo s 浏览器输入localhost:4000，查看主题是否成功。 7、给博客绑定域名 项目添加域名 12345$ cd hexo/public$ echo www.xxx.com &gt; CNAME# 重新发布$ hexo g$ hexo d DNS设置 1234注册DNSPOD，添加域名192.30.252.153192.30.252.154以上为github提供的ip 等待DNS刷新可能需要等待一段时间。 8、写文章并发布路径hexo\\source_posts下新建文件就可以了 XXX.md使用Markdown语法进行书写简书Markdown语法指南注意：文档最上面写 Q&amp;A1、搭建 hexo，在执行 hexo deploy 后,出现 error deployer not found:github 的错误 npm install hexo-deployer-git –save 改了之后执行，然后再部署试试","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/categories/Hexo/"}],"tags":[{"name":"node","slug":"node","permalink":"http://yoursite.com/tags/node/"},{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"},{"name":"npm","slug":"npm","permalink":"http://yoursite.com/tags/npm/"}]}]}